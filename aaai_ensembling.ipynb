{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "aaai_ensembling.ipynb",
      "provenance": [],
      "toc_visible": true,
      "authorship_tag": "ABX9TyPVi00pcr81MrzUIaBkqq8V",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/oldaandozerskaya/covid_news/blob/main/aaai_ensembling.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HKasI1R2gkYW",
        "outputId": "b2d8ec72-fae8-4237-a336-b3cc4c5ab973"
      },
      "source": [
        "from google.colab import drive\r\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VchQY7ZZlPUk"
      },
      "source": [
        "input = 'Covid-19 is absolutely safe'\r\n",
        "\r\n",
        "path = '/content/drive/My Drive/covid_fake_news/ct_model'"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3E9ZdsQllBDH"
      },
      "source": [
        "#import libs"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hcYN29Vak5HB",
        "outputId": "ce7a0755-6604-49d7-cb7f-6f7162da9018"
      },
      "source": [
        "import numpy as np\r\n",
        "\r\n",
        "!pip install transformers\r\n",
        "import transformers\r\n",
        "from transformers import BertForSequenceClassification, BertTokenizer\r\n",
        "\r\n",
        "import torch\r\n",
        "\r\n",
        "!pip install tweet-preprocessor\r\n",
        "import preprocessor as pp\r\n",
        "\r\n",
        "pp.set_options(pp.OPT.URL)\r\n",
        "\r\n",
        "!pip install emoji\r\n",
        "import emoji"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: transformers in /usr/local/lib/python3.6/dist-packages (4.0.1)\n",
            "Requirement already satisfied: tokenizers==0.9.4 in /usr/local/lib/python3.6/dist-packages (from transformers) (0.9.4)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.6/dist-packages (from transformers) (20.7)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.6/dist-packages (from transformers) (2.23.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from transformers) (1.18.5)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.6/dist-packages (from transformers) (2019.12.20)\n",
            "Requirement already satisfied: sacremoses in /usr/local/lib/python3.6/dist-packages (from transformers) (0.0.43)\n",
            "Requirement already satisfied: dataclasses; python_version < \"3.7\" in /usr/local/lib/python3.6/dist-packages (from transformers) (0.8)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.6/dist-packages (from transformers) (3.0.12)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.6/dist-packages (from transformers) (4.41.1)\n",
            "Requirement already satisfied: pyparsing>=2.0.2 in /usr/local/lib/python3.6/dist-packages (from packaging->transformers) (2.4.7)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (1.24.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (2020.12.5)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (3.0.4)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (2.10)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers) (1.15.0)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers) (0.17.0)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers) (7.1.2)\n",
            "Requirement already satisfied: tweet-preprocessor in /usr/local/lib/python3.6/dist-packages (0.6.0)\n",
            "Requirement already satisfied: emoji in /usr/local/lib/python3.6/dist-packages (0.6.0)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3vItf3DRlNOB"
      },
      "source": [
        "#text preprocessing"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mkGYpD5NloqT"
      },
      "source": [
        "text = pp.tokenize(input)\r\n",
        "text = emoji.demojize(text)\r\n",
        "text = text.lower()"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yhw9NBDOmUzF",
        "outputId": "96229a2a-d42b-466b-aff2-db4baf8d7119"
      },
      "source": [
        "model_name = 'digitalepidemiologylab/covid-twitter-bert'\r\n",
        "tokenizer = BertTokenizer.from_pretrained(model_name)\r\n",
        "\r\n",
        "input_ids = []\r\n",
        "attention_masks = []\r\n",
        "encoded_dict = tokenizer.encode_plus(\r\n",
        "                        text,                    \r\n",
        "                        truncation = True,\r\n",
        "                        add_special_tokens = True, \r\n",
        "                        max_length = 128,           \r\n",
        "                        pad_to_max_length = True,\r\n",
        "                        return_attention_mask = True,   \r\n",
        "                        return_tensors = 'pt',    \r\n",
        "                   )\r\n",
        "input_ids.append(encoded_dict['input_ids'])\r\n",
        "attention_masks.append(encoded_dict['attention_mask'])\r\n",
        "\r\n",
        "input_ids = torch.cat(input_ids, dim=0)\r\n",
        "attention_masks = torch.cat(attention_masks, dim=0)"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/transformers/tokenization_utils_base.py:2142: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "k2xS6it9mOux"
      },
      "source": [
        "#load models and predict\r\n",
        "\r\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3p6NLh7ssYGw"
      },
      "source": [
        "prediction = []\r\n",
        "for i in range(1,4):\r\n",
        "  pytorch_model = BertForSequenceClassification.from_pretrained(path + str(i) + '/', from_tf=False)\r\n",
        "  output = pytorch_model(input_ids, attention_masks)[0].detach().cpu().numpy()\r\n",
        "  prediction.append(output)\r\n",
        "\r\n",
        "del(pytorch_model)"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "tZkzhKaDzrMi",
        "outputId": "9e22f4cf-879a-4ca5-939e-6d3a15d7431b"
      },
      "source": [
        "flat_prediction = [item for sublist in prediction for item in sublist]\r\n",
        "flat_prediction = np.argmax(flat_prediction, axis=1).flatten()\r\n",
        "result = 'fake' if np.sum(flat_prediction)>1 else 'real'\r\n",
        "result"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'fake'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 11
        }
      ]
    }
  ]
}