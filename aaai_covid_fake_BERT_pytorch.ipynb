{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "aaai_covid_fake_BERT_pytorch.ipynb",
      "provenance": [],
      "collapsed_sections": [
        "OdPaGccVD7Ip",
        "bMwx6nm8Eex7",
        "mbl9S6rbE8PP"
      ],
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/oldaandozerskaya/covid_news/blob/main/aaai_covid_fake_BERT_pytorch.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wylmMx3bEH8I",
        "outputId": "35d4dee3-c5c3-4c79-af27-e056d25adc01",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OdPaGccVD7Ip"
      },
      "source": [
        "#Import libs"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DEfSbAA4QHas",
        "outputId": "97c1dfd4-f683-4890-ec82-e72f5d09e2d8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "import tensorflow as tf\n",
        "import pickle, os\n",
        "import math\n",
        "\n",
        "device_name = tf.test.gpu_device_name()\n",
        "if device_name != '/device:GPU:0':\n",
        "  raise SystemError('GPU device not found')\n",
        "print('Found GPU at: {}'.format(device_name))\n",
        "\n",
        "!pip install pytorch-pretrained-bert pytorch-nlp\n",
        "\n",
        "import torch\n",
        "from torch.utils.data import TensorDataset, DataLoader, RandomSampler, SequentialSampler\n",
        "\n",
        "import keras\n",
        "from keras import Sequential\n",
        "from keras.preprocessing.text import Tokenizer\n",
        "from keras.preprocessing.sequence import pad_sequences\n",
        "from keras.utils import to_categorical\n",
        "\n",
        "from keras.layers import Input, Embedding, Activation, Flatten, Dense, concatenate\n",
        "from keras.layers import Conv1D, MaxPooling1D, Dropout, LSTM\n",
        "from keras.models import Model\n",
        "from keras.preprocessing.sequence import pad_sequences\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "from pytorch_pretrained_bert import BertTokenizer, BertConfig, OpenAIGPTModel, OpenAIGPTTokenizer\n",
        "from pytorch_pretrained_bert import BertAdam, BertForSequenceClassification\n",
        "\n",
        "from tqdm import tqdm, trange\n",
        "import pandas as pd\n",
        "import io\n",
        "import numpy as np\n",
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "n_gpu = torch.cuda.device_count()\n",
        "torch.cuda.get_device_name(0)\n",
        "\n",
        "!pip install sentence-transformers\n",
        "from sentence_transformers import SentenceTransformer\n",
        "\n",
        "from sklearn.metrics import accuracy_score, f1_score, recall_score, precision_score"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Found GPU at: /device:GPU:0\n",
            "Collecting pytorch-pretrained-bert\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/d7/e0/c08d5553b89973d9a240605b9c12404bcf8227590de62bae27acbcfe076b/pytorch_pretrained_bert-0.6.2-py3-none-any.whl (123kB)\n",
            "\u001b[K     |████████████████████████████████| 133kB 4.5MB/s \n",
            "\u001b[?25hCollecting pytorch-nlp\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/4f/51/f0ee1efb75f7cc2e3065c5da1363d6be2eec79691b2821594f3f2329528c/pytorch_nlp-0.5.0-py3-none-any.whl (90kB)\n",
            "\u001b[K     |████████████████████████████████| 92kB 8.0MB/s \n",
            "\u001b[?25hRequirement already satisfied: requests in /usr/local/lib/python3.6/dist-packages (from pytorch-pretrained-bert) (2.23.0)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.6/dist-packages (from pytorch-pretrained-bert) (4.41.1)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from pytorch-pretrained-bert) (1.18.5)\n",
            "Requirement already satisfied: regex in /usr/local/lib/python3.6/dist-packages (from pytorch-pretrained-bert) (2019.12.20)\n",
            "Collecting boto3\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/2f/08/f1ff665147a5d75b871bbe5ba76916f6490419c52a33e588385c4b69281b/boto3-1.15.18-py2.py3-none-any.whl (129kB)\n",
            "\u001b[K     |████████████████████████████████| 133kB 8.8MB/s \n",
            "\u001b[?25hRequirement already satisfied: torch>=0.4.1 in /usr/local/lib/python3.6/dist-packages (from pytorch-pretrained-bert) (1.6.0+cu101)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests->pytorch-pretrained-bert) (1.24.3)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests->pytorch-pretrained-bert) (2.10)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests->pytorch-pretrained-bert) (2020.6.20)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests->pytorch-pretrained-bert) (3.0.4)\n",
            "Collecting botocore<1.19.0,>=1.18.18\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/2d/72/984ac8f33b5c8df5ff63f323a8724f65b4d0f8956968b942b77d35d3a1ef/botocore-1.18.18-py2.py3-none-any.whl (6.7MB)\n",
            "\u001b[K     |████████████████████████████████| 6.7MB 11.0MB/s \n",
            "\u001b[?25hCollecting s3transfer<0.4.0,>=0.3.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/69/79/e6afb3d8b0b4e96cefbdc690f741d7dd24547ff1f94240c997a26fa908d3/s3transfer-0.3.3-py2.py3-none-any.whl (69kB)\n",
            "\u001b[K     |████████████████████████████████| 71kB 9.6MB/s \n",
            "\u001b[?25hCollecting jmespath<1.0.0,>=0.7.1\n",
            "  Downloading https://files.pythonhosted.org/packages/07/cb/5f001272b6faeb23c1c9e0acc04d48eaaf5c862c17709d20e3469c6e0139/jmespath-0.10.0-py2.py3-none-any.whl\n",
            "Requirement already satisfied: future in /usr/local/lib/python3.6/dist-packages (from torch>=0.4.1->pytorch-pretrained-bert) (0.16.0)\n",
            "Requirement already satisfied: python-dateutil<3.0.0,>=2.1 in /usr/local/lib/python3.6/dist-packages (from botocore<1.19.0,>=1.18.18->boto3->pytorch-pretrained-bert) (2.8.1)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.6/dist-packages (from python-dateutil<3.0.0,>=2.1->botocore<1.19.0,>=1.18.18->boto3->pytorch-pretrained-bert) (1.15.0)\n",
            "Installing collected packages: jmespath, botocore, s3transfer, boto3, pytorch-pretrained-bert, pytorch-nlp\n",
            "Successfully installed boto3-1.15.18 botocore-1.18.18 jmespath-0.10.0 pytorch-nlp-0.5.0 pytorch-pretrained-bert-0.6.2 s3transfer-0.3.3\n",
            "Collecting sentence-transformers\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/ce/4b/0add07b1eebbbe83e77fb5ac4e72e87046c3fc2c9cb16f7d1cd8c6921a1d/sentence-transformers-0.3.7.2.tar.gz (59kB)\n",
            "\u001b[K     |████████████████████████████████| 61kB 2.9MB/s \n",
            "\u001b[?25hCollecting transformers<3.4.0,>=3.1.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/19/22/aff234f4a841f8999e68a7a94bdd4b60b4cebcfeca5d67d61cd08c9179de/transformers-3.3.1-py3-none-any.whl (1.1MB)\n",
            "\u001b[K     |████████████████████████████████| 1.1MB 7.6MB/s \n",
            "\u001b[?25hRequirement already satisfied: tqdm in /usr/local/lib/python3.6/dist-packages (from sentence-transformers) (4.41.1)\n",
            "Requirement already satisfied: torch>=1.2.0 in /usr/local/lib/python3.6/dist-packages (from sentence-transformers) (1.6.0+cu101)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from sentence-transformers) (1.18.5)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.6/dist-packages (from sentence-transformers) (0.22.2.post1)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.6/dist-packages (from sentence-transformers) (1.4.1)\n",
            "Requirement already satisfied: nltk in /usr/local/lib/python3.6/dist-packages (from sentence-transformers) (3.2.5)\n",
            "Collecting tokenizers==0.8.1.rc2\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/80/83/8b9fccb9e48eeb575ee19179e2bdde0ee9a1904f97de5f02d19016b8804f/tokenizers-0.8.1rc2-cp36-cp36m-manylinux1_x86_64.whl (3.0MB)\n",
            "\u001b[K     |████████████████████████████████| 3.0MB 14.7MB/s \n",
            "\u001b[?25hCollecting sentencepiece!=0.1.92\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/d4/a4/d0a884c4300004a78cca907a6ff9a5e9fe4f090f5d95ab341c53d28cbc58/sentencepiece-0.1.91-cp36-cp36m-manylinux1_x86_64.whl (1.1MB)\n",
            "\u001b[K     |████████████████████████████████| 1.1MB 51.6MB/s \n",
            "\u001b[?25hRequirement already satisfied: requests in /usr/local/lib/python3.6/dist-packages (from transformers<3.4.0,>=3.1.0->sentence-transformers) (2.23.0)\n",
            "Collecting sacremoses\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/7d/34/09d19aff26edcc8eb2a01bed8e98f13a1537005d31e95233fd48216eed10/sacremoses-0.0.43.tar.gz (883kB)\n",
            "\u001b[K     |████████████████████████████████| 890kB 52.1MB/s \n",
            "\u001b[?25hRequirement already satisfied: dataclasses; python_version < \"3.7\" in /usr/local/lib/python3.6/dist-packages (from transformers<3.4.0,>=3.1.0->sentence-transformers) (0.7)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.6/dist-packages (from transformers<3.4.0,>=3.1.0->sentence-transformers) (2019.12.20)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.6/dist-packages (from transformers<3.4.0,>=3.1.0->sentence-transformers) (20.4)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.6/dist-packages (from transformers<3.4.0,>=3.1.0->sentence-transformers) (3.0.12)\n",
            "Requirement already satisfied: future in /usr/local/lib/python3.6/dist-packages (from torch>=1.2.0->sentence-transformers) (0.16.0)\n",
            "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.6/dist-packages (from scikit-learn->sentence-transformers) (0.16.0)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from nltk->sentence-transformers) (1.15.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests->transformers<3.4.0,>=3.1.0->sentence-transformers) (2020.6.20)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests->transformers<3.4.0,>=3.1.0->sentence-transformers) (2.10)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests->transformers<3.4.0,>=3.1.0->sentence-transformers) (1.24.3)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests->transformers<3.4.0,>=3.1.0->sentence-transformers) (3.0.4)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers<3.4.0,>=3.1.0->sentence-transformers) (7.1.2)\n",
            "Requirement already satisfied: pyparsing>=2.0.2 in /usr/local/lib/python3.6/dist-packages (from packaging->transformers<3.4.0,>=3.1.0->sentence-transformers) (2.4.7)\n",
            "Building wheels for collected packages: sentence-transformers, sacremoses\n",
            "  Building wheel for sentence-transformers (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for sentence-transformers: filename=sentence_transformers-0.3.7.2-cp36-none-any.whl size=91190 sha256=14cb2f7e64f779b813c4357c456ced9f240b5bbec83c1362dcefba18de63494d\n",
            "  Stored in directory: /root/.cache/pip/wheels/4b/8f/23/7f93e91176acc7c2d651b54fa9f01e3624a47904145c4d133e\n",
            "  Building wheel for sacremoses (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for sacremoses: filename=sacremoses-0.0.43-cp36-none-any.whl size=893257 sha256=2c7ca1c8b5a08ce065a7fb9489b30151f78151650108125e4a742a33cc9f5b36\n",
            "  Stored in directory: /root/.cache/pip/wheels/29/3c/fd/7ce5c3f0666dab31a50123635e6fb5e19ceb42ce38d4e58f45\n",
            "Successfully built sentence-transformers sacremoses\n",
            "Installing collected packages: tokenizers, sentencepiece, sacremoses, transformers, sentence-transformers\n",
            "Successfully installed sacremoses-0.0.43 sentence-transformers-0.3.7.2 sentencepiece-0.1.91 tokenizers-0.8.1rc2 transformers-3.3.1\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bMwx6nm8Eex7"
      },
      "source": [
        "#Import data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4gDpOPc5EcRE",
        "outputId": "e7df9ad8-936b-4a92-c4c5-01c41924053e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        }
      },
      "source": [
        "df = pd.read_csv('/content/drive/My Drive/covid_fake_news/Constraint_English_Train.csv')\n",
        "df.head()"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>tweet</th>\n",
              "      <th>label</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>The CDC currently reports 99031 deaths. In gen...</td>\n",
              "      <td>real</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2</td>\n",
              "      <td>States reported 1121 deaths a small rise from ...</td>\n",
              "      <td>real</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>3</td>\n",
              "      <td>Politically Correct Woman (Almost) Uses Pandem...</td>\n",
              "      <td>fake</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>4</td>\n",
              "      <td>#IndiaFightsCorona: We have 1524 #COVID testin...</td>\n",
              "      <td>real</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>5</td>\n",
              "      <td>Populous states can generate large case counts...</td>\n",
              "      <td>real</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   id                                              tweet label\n",
              "0   1  The CDC currently reports 99031 deaths. In gen...  real\n",
              "1   2  States reported 1121 deaths a small rise from ...  real\n",
              "2   3  Politically Correct Woman (Almost) Uses Pandem...  fake\n",
              "3   4  #IndiaFightsCorona: We have 1524 #COVID testin...  real\n",
              "4   5  Populous states can generate large case counts...  real"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tONIp3ONEnE3",
        "outputId": "06276a8c-35cb-43e2-e33a-157aad5058c4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 72
        }
      },
      "source": [
        "df['label'].value_counts()"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "real    3360\n",
              "fake    3060\n",
              "Name: label, dtype: int64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eCWwcbmXEp0h"
      },
      "source": [
        "train_texts = df.tweet.values\n",
        "df['label'] = df['label'].map({'fake': 1, 'real': 0})\n",
        "train_labels = df.label.values"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gt0UjpTnEvlx",
        "outputId": "00382045-ac21-4b22-8e1d-6e7ba6977ee7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        }
      },
      "source": [
        "df = pd.read_csv('/content/drive/My Drive/covid_fake_news/Constraint_English_Val.csv')\n",
        "df.head()"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>tweet</th>\n",
              "      <th>label</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>Chinese converting to Islam after realising th...</td>\n",
              "      <td>fake</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2</td>\n",
              "      <td>11 out of 13 people (from the Diamond Princess...</td>\n",
              "      <td>fake</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>3</td>\n",
              "      <td>COVID-19 Is Caused By A Bacterium, Not Virus A...</td>\n",
              "      <td>fake</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>4</td>\n",
              "      <td>Mike Pence in RNC speech praises Donald Trump’...</td>\n",
              "      <td>fake</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>5</td>\n",
              "      <td>6/10 Sky's @EdConwaySky explains the latest #C...</td>\n",
              "      <td>real</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   id                                              tweet label\n",
              "0   1  Chinese converting to Islam after realising th...  fake\n",
              "1   2  11 out of 13 people (from the Diamond Princess...  fake\n",
              "2   3  COVID-19 Is Caused By A Bacterium, Not Virus A...  fake\n",
              "3   4  Mike Pence in RNC speech praises Donald Trump’...  fake\n",
              "4   5  6/10 Sky's @EdConwaySky explains the latest #C...  real"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "532bsy8ZEzeG",
        "outputId": "163dcdf5-7e33-4b1e-e93c-7f04e24d32a6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 72
        }
      },
      "source": [
        "df['label'].value_counts()"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "real    1120\n",
              "fake    1020\n",
              "Name: label, dtype: int64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sMwhYpUKE1kx"
      },
      "source": [
        "val_texts = df.tweet.values\n",
        "df['label'] = df['label'].map({'fake': 1, 'real': 0})\n",
        "val_labels = df.label.values"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mbl9S6rbE8PP"
      },
      "source": [
        "#BERT binary classifier"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YwtDAPSTmHBg"
      },
      "source": [
        "train_sentences = [\"[CLS] \" + text + \" [SEP]\" for text in train_texts]\n",
        "val_sentences = [\"[CLS] \" + text + \" [SEP]\" for text in val_texts]"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Z474sSC6oe7A",
        "outputId": "fb0e7a1b-1a1b-4b94-afdf-1bf5f1af4536",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 92
        }
      },
      "source": [
        "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased', do_lower_case=True)\n",
        "tokenized_texts = [tokenizer.tokenize(text) for text in train_sentences]\n",
        "\n",
        "print (\"Tokenize the first sentence:\")\n",
        "print (tokenized_texts[0])"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 231508/231508 [00:00<00:00, 890791.99B/s]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Tokenize the first sentence:\n",
            "['[CLS]', 'the', 'cdc', 'currently', 'reports', '99', '##0', '##31', 'deaths', '.', 'in', 'general', 'the', 'disc', '##re', '##pan', '##cies', 'in', 'death', 'counts', 'between', 'different', 'sources', 'are', 'small', 'and', 'ex', '##pl', '##ica', '##ble', '.', 'the', 'death', 'toll', 'stands', 'at', 'roughly', '1000', '##00', 'people', 'today', '.', '[SEP]']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mFhowDMohU4H",
        "outputId": "cd46602f-111d-497e-e44f-d2a4aeedbadc",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 74
        }
      },
      "source": [
        "input_ids = [tokenizer.convert_tokens_to_ids(x) for x in tokenized_texts]\n",
        "input_ids = pad_sequences(input_ids, maxlen=128, dtype=\"long\", truncating=\"post\", padding=\"post\")\n",
        "attention_masks = []\n",
        "\n",
        "for seq in input_ids:\n",
        "  seq_mask = [float(i>0) for i in seq]\n",
        "  attention_masks.append(seq_mask)"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (1885 > 512). Running this sequence through BERT will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (1112 > 512). Running this sequence through BERT will result in indexing errors\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aFbE-UHvsb7-"
      },
      "source": [
        "train_inputs, validation_inputs, train_labels, validation_labels = train_test_split(input_ids, train_labels, \n",
        "                                                            random_state=42, test_size=0.2)\n",
        "train_masks, validation_masks, _, _ = train_test_split(attention_masks, input_ids,\n",
        "                                             random_state=42, test_size=0.2)"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jw5K2A5Ko1RF"
      },
      "source": [
        "train_inputs = torch.tensor(train_inputs)\n",
        "validation_inputs = torch.tensor(validation_inputs)\n",
        "train_labels = torch.tensor(train_labels)\n",
        "validation_labels = torch.tensor(validation_labels)\n",
        "train_masks = torch.tensor(train_masks)\n",
        "validation_masks = torch.tensor(validation_masks)"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GEgLpFVlo1Z-"
      },
      "source": [
        "# Select a batch size for training. For fine-tuning BERT on a specific task, the authors recommend a batch size of 16 or 32\n",
        "batch_size = 8\n",
        "\n",
        "# Create an iterator of our data with torch DataLoader. This helps save on memory during training because, unlike a for loop, \n",
        "# with an iterator the entire dataset does not need to be loaded into memory\n",
        "\n",
        "train_data = TensorDataset(train_inputs, train_masks, train_labels)\n",
        "train_sampler = RandomSampler(train_data)\n",
        "train_dataloader = DataLoader(train_data, sampler=train_sampler, batch_size=batch_size)\n",
        "\n",
        "validation_data = TensorDataset(validation_inputs, validation_masks, validation_labels)\n",
        "validation_sampler = SequentialSampler(validation_data)\n",
        "validation_dataloader = DataLoader(validation_data, sampler=validation_sampler, batch_size=batch_size)\n"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gFsCTp_mporB",
        "outputId": "c9149432-8425-4e1b-8e43-b572e1f2a0cb",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "model = BertForSequenceClassification.from_pretrained(\"bert-base-uncased\", num_labels=2)\n",
        "model.cuda()"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 407873900/407873900 [00:11<00:00, 36422517.20B/s]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "BertForSequenceClassification(\n",
              "  (bert): BertModel(\n",
              "    (embeddings): BertEmbeddings(\n",
              "      (word_embeddings): Embedding(30522, 768, padding_idx=0)\n",
              "      (position_embeddings): Embedding(512, 768)\n",
              "      (token_type_embeddings): Embedding(2, 768)\n",
              "      (LayerNorm): BertLayerNorm()\n",
              "      (dropout): Dropout(p=0.1, inplace=False)\n",
              "    )\n",
              "    (encoder): BertEncoder(\n",
              "      (layer): ModuleList(\n",
              "        (0): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): BertLayerNorm()\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): BertLayerNorm()\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (1): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): BertLayerNorm()\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): BertLayerNorm()\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (2): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): BertLayerNorm()\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): BertLayerNorm()\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (3): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): BertLayerNorm()\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): BertLayerNorm()\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (4): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): BertLayerNorm()\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): BertLayerNorm()\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (5): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): BertLayerNorm()\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): BertLayerNorm()\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (6): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): BertLayerNorm()\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): BertLayerNorm()\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (7): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): BertLayerNorm()\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): BertLayerNorm()\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (8): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): BertLayerNorm()\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): BertLayerNorm()\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (9): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): BertLayerNorm()\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): BertLayerNorm()\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (10): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): BertLayerNorm()\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): BertLayerNorm()\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (11): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): BertLayerNorm()\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): BertLayerNorm()\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "      )\n",
              "    )\n",
              "    (pooler): BertPooler(\n",
              "      (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "      (activation): Tanh()\n",
              "    )\n",
              "  )\n",
              "  (dropout): Dropout(p=0.1, inplace=False)\n",
              "  (classifier): Linear(in_features=768, out_features=2, bias=True)\n",
              ")"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QxSMw0FrptiL"
      },
      "source": [
        "param_optimizer = list(model.named_parameters())\n",
        "no_decay = ['bias', 'gamma', 'beta']\n",
        "optimizer_grouped_parameters = [\n",
        "    {'params': [p for n, p in param_optimizer if not any(nd in n for nd in no_decay)],\n",
        "     'weight_decay_rate': 0.01},\n",
        "    {'params': [p for n, p in param_optimizer if any(nd in n for nd in no_decay)],\n",
        "     'weight_decay_rate': 0.0}\n",
        "]"
      ],
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GLs72DuMODJO",
        "outputId": "6b99204f-881b-4b3f-b647-405462e1b5a4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "optimizer = BertAdam(optimizer_grouped_parameters,\n",
        "                     lr=2e-5,\n",
        "                     warmup=.1)"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "t_total value of -1 results in schedule not being applied\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9cQNvaZ9bnyy"
      },
      "source": [
        "def flat_accuracy(preds, labels):\n",
        "    pred_flat = np.argmax(preds, axis=1).flatten()\n",
        "    labels_flat = labels.flatten()\n",
        "    return np.sum(pred_flat == labels_flat) / len(labels_flat)"
      ],
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6J-FYdx6nFE_",
        "outputId": "4842f1f1-230c-4095-caff-024c10bab425",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 257
        }
      },
      "source": [
        "train_loss_set = []\n",
        "\n",
        "# Number of training epochs (authors recommend between 2 and 4)\n",
        "epochs = 3\n",
        "\n",
        "# trange is a tqdm wrapper around the normal python range\n",
        "for _ in trange(epochs, desc=\"Epoch\"):\n",
        "  \n",
        "  \n",
        "  # Training\n",
        "  \n",
        "  # Set our model to training mode (as opposed to evaluation mode)\n",
        "  model.train()\n",
        "  \n",
        "  # Tracking variables\n",
        "  tr_loss = 0\n",
        "  nb_tr_examples, nb_tr_steps = 0, 0\n",
        "  \n",
        "  # Train the data for one epoch\n",
        "  for step, batch in enumerate(train_dataloader):\n",
        "    # Add batch to GPU\n",
        "    batch = tuple(t.to(device) for t in batch)\n",
        "    # Unpack the inputs from our dataloader\n",
        "    b_input_ids, b_input_mask, b_labels = batch\n",
        "    # Clear out the gradients (by default they accumulate)\n",
        "    optimizer.zero_grad()\n",
        "    # Forward pass\n",
        "    loss = model(b_input_ids, token_type_ids=None, attention_mask=b_input_mask, labels=b_labels)\n",
        "\n",
        "    train_loss_set.append(loss.item())    \n",
        "    # Backward pass\n",
        "    loss.backward()\n",
        "    # Update parameters and take a step using the computed gradient\n",
        "    optimizer.step()\n",
        "    \n",
        "    \n",
        "    # Update tracking variables\n",
        "    tr_loss += loss.item()\n",
        "    nb_tr_examples += b_input_ids.size(0)\n",
        "    nb_tr_steps += 1\n",
        "\n",
        "  print(\"Train loss: {}\".format(tr_loss/nb_tr_steps))\n",
        "    \n",
        "    \n",
        "  # Validation\n",
        "\n",
        "  # Put model in evaluation mode to evaluate loss on the validation set\n",
        "  model.eval()\n",
        "\n",
        "  # Tracking variables \n",
        "  eval_loss, eval_accuracy = 0, 0\n",
        "  nb_eval_steps, nb_eval_examples = 0, 0\n",
        "  \n",
        "  # Evaluate data for one epoch\n",
        "  for batch in validation_dataloader:\n",
        "    # Add batch to GPU\n",
        "    batch = tuple(t.to(device) for t in batch)\n",
        "    # Unpack the inputs from our dataloader\n",
        "    b_input_ids, b_input_mask, b_labels = batch\n",
        "    # Telling the model not to compute or store gradients, saving memory and speeding up validation\n",
        "    with torch.no_grad():\n",
        "      # Forward pass, calculate logit predictions\n",
        "      logits = model(b_input_ids, token_type_ids=None, attention_mask=b_input_mask)\n",
        "    \n",
        "    # Move logits and labels to CPU\n",
        "    logits = logits.detach().cpu().numpy()\n",
        "    label_ids = b_labels.to('cpu').numpy()\n",
        "\n",
        "    tmp_eval_accuracy = flat_accuracy(logits, label_ids)\n",
        "    \n",
        "    eval_accuracy += tmp_eval_accuracy\n",
        "    nb_eval_steps += 1\n",
        "\n",
        "  print(\"Validation Accuracy: {}\".format(eval_accuracy/nb_eval_steps))\n",
        "  "
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\rEpoch:   0%|          | 0/3 [00:00<?, ?it/s]/usr/local/lib/python3.6/dist-packages/pytorch_pretrained_bert/optimization.py:275: UserWarning: This overload of add_ is deprecated:\n",
            "\tadd_(Number alpha, Tensor other)\n",
            "Consider using one of the following signatures instead:\n",
            "\tadd_(Tensor other, *, Number alpha) (Triggered internally at  /pytorch/torch/csrc/utils/python_arg_parser.cpp:766.)\n",
            "  next_m.mul_(beta1).add_(1 - beta1, grad)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Train loss: 0.1943941493279292\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\rEpoch:  33%|███▎      | 1/3 [03:32<07:04, 212.40s/it]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Validation Accuracy: 0.9658385093167702\n",
            "Train loss: 0.04940920286508882\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\rEpoch:  67%|██████▋   | 2/3 [07:04<03:32, 212.29s/it]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Validation Accuracy: 0.9642857142857143\n",
            "Train loss: 0.014407573796933748\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch: 100%|██████████| 3/3 [10:35<00:00, 211.86s/it]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Validation Accuracy: 0.9635093167701864\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FAnAi5rjAOQR"
      },
      "source": [
        ""
      ],
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mAN0LZBOOPVh",
        "outputId": "b0e60294-f886-4097-fb3f-2017b24d8022",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 55
        }
      },
      "source": [
        "tokenized_texts_val = [tokenizer.tokenize(text) for text in val_sentences]\n",
        "input_ids = [tokenizer.convert_tokens_to_ids(x) for x in tokenized_texts_val]\n",
        "# Pad our input tokens\n",
        "input_ids = pad_sequences(input_ids, maxlen=128, dtype=\"long\", truncating=\"post\", padding=\"post\")\n",
        "# Create attention masks\n",
        "attention_masks = []\n",
        "\n",
        "# Create a mask of 1s for each token followed by 0s for padding\n",
        "for seq in input_ids:\n",
        "  seq_mask = [float(i>0) for i in seq]\n",
        "  attention_masks.append(seq_mask) \n",
        "\n",
        "prediction_inputs = torch.tensor(input_ids)\n",
        "prediction_masks = torch.tensor(attention_masks)\n",
        "prediction_labels = torch.tensor(val_labels)\n",
        "  \n",
        "batch_size = 8\n",
        "\n",
        "\n",
        "prediction_data = TensorDataset(prediction_inputs, prediction_masks, prediction_labels)\n",
        "prediction_sampler = SequentialSampler(prediction_data)\n",
        "prediction_dataloader = DataLoader(prediction_data, sampler=prediction_sampler, batch_size=batch_size)"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (609 > 512). Running this sequence through BERT will result in indexing errors\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Hba10sXR7Xi6"
      },
      "source": [
        "# Prediction on test set\n",
        "\n",
        "# Put model in evaluation mode\n",
        "model.eval()\n",
        "\n",
        "# Tracking variables \n",
        "predictions , true_labels = [], []\n",
        "\n",
        "# Predict \n",
        "for batch in prediction_dataloader:\n",
        "  # Add batch to GPU\n",
        "  batch = tuple(t.to(device) for t in batch)\n",
        "  # Unpack the inputs from our dataloader\n",
        "  b_input_ids, b_input_mask, b_labels = batch\n",
        "  # Telling the model not to compute or store gradients, saving memory and speeding up prediction\n",
        "  with torch.no_grad():\n",
        "    # Forward pass, calculate logit predictions\n",
        "    logits = model(b_input_ids, token_type_ids=None, attention_mask=b_input_mask)\n",
        "\n",
        "  # Move logits and labels to CPU\n",
        "  logits = logits.detach().cpu().numpy()\n",
        "  label_ids = b_labels.to('cpu').numpy()\n",
        "  \n",
        "  # Store predictions and true labels\n",
        "  predictions.append(logits)\n",
        "  true_labels.append(label_ids)"
      ],
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oCYZa1lQ8Jn8",
        "outputId": "2bf89191-d2b5-441d-a93d-ac7496e2a953",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 72
        }
      },
      "source": [
        "from sklearn.metrics import f1_score, recall_score, precision_score\n",
        "# Flatten the predictions and true values for aggregate Matthew's evaluation on the whole dataset\n",
        "flat_predictions = [item for sublist in predictions for item in sublist]\n",
        "flat_predictions = np.argmax(flat_predictions, axis=1).flatten()\n",
        "flat_true_labels = [item for sublist in true_labels for item in sublist]\n",
        "print('F1-score: %f' % (f1_score(flat_predictions, flat_true_labels)*100))\n",
        "print('Precision: %f' % (precision_score(flat_predictions, flat_true_labels)*100))\n",
        "print('Recall: %f' % (recall_score(flat_predictions, flat_true_labels)*100))"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "F1-score: 97.222222\n",
            "Precision: 96.078431\n",
            "Recall: 98.393574\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NFsxfY8jr-Uw"
      },
      "source": [
        "output_dir = '/content/drive/My Drive/covid_fake_news/bert/bert.bin'\n",
        "torch.save(model.state_dict(), output_dir)"
      ],
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rp6JbxulJzds",
        "outputId": "c0c10e06-cc56-4ad7-9ee3-df40877248e2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "for i, text in enumerate(val_texts):\n",
        "  if flat_predictions[i]!=flat_true_labels[i]:\n",
        "    print(flat_predictions[i])\n",
        "    print(flat_true_labels[i])\n",
        "    print(text)"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0\n",
            "1\n",
            "11 out of 13 people (from the Diamond Princess Cruise ship) who had intially tested negative in tests in Japan were later confirmed to be positive in the United States.\n",
            "0\n",
            "1\n",
            "Mike Pence introduces program to cure coronavirus carriers with conversion therapy https://t.co/A36KAO2NWa https://t.co/bp0SDO25F0\n",
            "0\n",
            "1\n",
            "WHO reports record daily increase in global coronavirus cases up over 292000 https://t.co/b0EtsTmqgb\n",
            "0\n",
            "1\n",
            "There is no evidence that children have died because of a COVID-19 vaccine. No vaccine currently in development has been approved for widespread public use. https://t.co/9ecvMR8SAf\n",
            "0\n",
            "1\n",
            "No one should have to pay for coronavirus treatment. Period. https://t.co/GBchrVZmDz\n",
            "1\n",
            "0\n",
            "Gargled water samples may be viable alternative to swabs for detection of COVID-19: Study https://t.co/feOauXK2sh\n",
            "0\n",
            "1\n",
            "The Canadian government has not enacted a law that criminalizes COVID-19 restrictions or prevents enforcement of those guidelines. https://t.co/c7IST1A1ip\n",
            "0\n",
            "1\n",
            "IACC is to Autism as \"X\" is to COVID https://t.co/447cYfVImc\n",
            "0\n",
            "1\n",
            "Study finds evidence of heart damage in college athletes with COVID-19 https://t.co/WVYOk4lfZN\n",
            "1\n",
            "0\n",
            "A reminder about maintaining good hygiene: wash your hands often cough or sneeze into your elbow and stay at home if you’re unwell.\n",
            "0\n",
            "1\n",
            "An article from April announcing a new study “connects” the flu vaccine and an increased risk of coronavirus is based on data from 2017-18 and doesn’t include COVID-19. https://t.co/sIh5mE3hdP\n",
            "0\n",
            "1\n",
            "Highest cases &amp; highest deaths in a day in #Pakistan. Total cases crossed 50,000. Ease of lockdown was to keep economy wheel rolling but we have taken it as #CoronaInPakistan ended. Everyone needs to understand before its too late that #COVIDー19 is a harsh reality. \n",
            "Take Care 🙏 https://t.co/ItDuhAnyhL\n",
            "1\n",
            "0\n",
            "How deadly is the coronavirus #COVID19? Scientists are close to an answer @nresearchnews Infection fatality rate explained by Robert Verity @MRC_Outbreak and Timothy Russell @LSHTM https://t.co/9lw9RSXnnd\n",
            "1\n",
            "0\n",
            "An independent #CODECHECK review @StephenEglen confirmed that the Imperial #COVID19 Report 9 code is reproducible as scripts and documentation are published 🔰https://t.co/0SW9DsFsIM\n",
            "0\n",
            "1\n",
            "Study Shows Most Americans Prefer Indefinite Isolation to Giving Up Bacon https://t.co/7C9spV5V7v #nashville #meat #vegan #pandemic\n",
            "0\n",
            "1\n",
            "How has alcohol consumption changed during lockdown? Read our latest #CPD article for more information on how drinking habits have changed during the pandemic and the short-term and long-term effects of alcohol misuse\n",
            "@Drinkaware @AlcoholChangeUK \n",
            "\n",
            "https://t.co/jNV645L7Il https://t.co/gGpNZShIPl\n",
            "1\n",
            "0\n",
            "As for the Russian COVID vaccine Fauci is among the doubters. https://t.co/ged4pZv475\n",
            "0\n",
            "1\n",
            "#VitaminD is now in focus to prevent #Coronavirus . Know if your body has enough of it. https://t.co/OFWcLha5ef\n",
            "0\n",
            "1\n",
            "Wasting VALUABLE resources &amp; risking millions more lives at the same time.\n",
            "\n",
            "Whatever he releases doesn't even have to be a vaccine. He signed an executive order to proclaim EUA for any bs he calls a cure.\n",
            "\n",
            "It could actually be Lysol. Who thinks he wouldn't okay injecting poison? https://t.co/WlQ0tSsx59\n",
            "1\n",
            "0\n",
            "A podcast on how to best educate patients about COVID-19 🦠 https://t.co/jmNiUAFRvB https://t.co/Ec2ay1CpTd\n",
            "0\n",
            "1\n",
            "RT @dpfunke: A data table from the World Bank is causing a lot of confusion about coronavirus testing equipment. To be clear: COVID-19 tes…\n",
            "1\n",
            "0\n",
            "-Complying with all MoH guidelines -staying 2m apart from people outside their bubble washing their hands coughing into their elbow -Not attending supermarkets shops petrol station or similar services.\n",
            "0\n",
            "1\n",
            "We're still a long way away from herd immunity from COVID-19 in the United States. https://t.co/kVXlIkeDRa https://t.co/RC3BNj0ktG\n",
            "1\n",
            "0\n",
            "Will California’s governor approve the $150 million per year needed to battle #COVID19? https://t.co/JHgh4gn0dR\n",
            "1\n",
            "0\n",
            "#ZuckOff #TakeItFromADoctor and a video with false claims on mask wearing and #hydroxychloroquine. https://t.co/0WH13B5iqT https://t.co/04eETBikNd\n",
            "1\n",
            "0\n",
            "Hollywood actor Paul Rudd has encouraged young people to wear face masks in an entertaining video as the US grapples with the #COVID19 pandemic https://t.co/0uEqyLlCna\n",
            "0\n",
            "1\n",
            "First case of coronavirus traced to Marine putting hands in pockets https://t.co/a6vN4vpwGX\n",
            "0\n",
            "1\n",
            "In February CDC Director Robert Redfield said healthy people shouldn't wear masks — but that advice is long outdated. This month he said they're our best defense against COVID-19. https://t.co/bgWYjTjkBE\n",
            "1\n",
            "0\n",
            "Looking for ways to help while Quarantined? 🍔 Support local businesses by ordering takeout or buying gift cards ❤️ Donate blood via @RedCross 🥫 Donate to your local food banks ☎️ Check in with your neighbors especially those living alone Most Importantly #StayAtHome\n",
            "1\n",
            "0\n",
            "#IndiaFightsCorona: 📍 Epidemic diseases (amendment) ordinance 2020 ➡️ Attacks on doctors and health workers now a grave offence ➡️ A jail term term of up to 7 years and fine upto Rs 5 lakh ➡️ Cases to be investigated within 30 days and verdict within a year #StaySafe https://t.co/1rgx4JM1yr\n",
            "0\n",
            "1\n",
            "How South Korea Successfully Managed Coronavirus\n",
            "https://t.co/ImojhnSrgm\n",
            "The nation fast-tracked approval of domestic testing kits as soon as cases began hitting.\n",
            "1\n",
            "0\n",
            "Should doctors be free from #malpractice lawsuits stemming from delayed treatments as result of #COVID? https://t.co/pzlWBfUred\n",
            "0\n",
            "1\n",
            "Vitamin D can help reduce coronavirus risk by 54%\n",
            "\n",
            "https://t.co/0EpQSWpGfv\n",
            "0\n",
            "1\n",
            "Children do contract the coronavirus but current research shows it is happening at a much lower rate than for adults. https://t.co/GW4aSvUOst\n",
            "0\n",
            "1\n",
            "PM @ScottMorrisonMP recently said a #COVID19 vaccine would be \"as mandatory as you can possibly make it\". But what does that mean? Experts we spoke to said it was unlikely the vaccination could be forced upon the population in Australia. Here's why: https://t.co/8axB6BPplC https://t.co/tb5CpYQiIr\n",
            "0\n",
            "1\n",
            "A @Target spokesperson said the company plans to continue “Heroes &amp; Helpers” an event that pairs underserved children with officers to shop for holiday gifts. The company says careful considerations are underway on how to manage the event amid COVID-19. https://t.co/WdHJ3zkMQn\n",
            "0\n",
            "1\n",
            "At this Critical Scenario We need full fledged 25 teams of 100 lab technicians under 2 MicroBiologists (for Virtual Administration) needed. Train All Graduate teachers of KA to test COVID 19 Samples We can do this ..@BSYBJP @mla_sudhakar @csogok @ChangeOrg_India @narendramodi https://t.co/EV2r2fOkeh\n",
            "0\n",
            "1\n",
            "Little Free Library implements more comprehensive Covid-19 strategy than White House https://t.co/1opJ1ujM5X https://t.co/8IpsFZlCPC\n",
            "0\n",
            "1\n",
            "@thereidout @JoyAnnReid Airborne #COVID19 is the pre-existing condition that’ll financially bury American #families whose states’ governors are manipulating #data to force #children back into #school w recirculated air conditioning which cannot be economically &amp; adequately disinfected. #WarCrimes https://t.co/000wAOE6E1\n",
            "0\n",
            "1\n",
            "Union Home Minister Amit Shah tested negative for coronavirus. Union Health Ministry Joint Secretary Lav Agarwal tested positive for COVID-19 and is currently in home isolation as per guidelines. #Covid_19 #IndependenceDay #IndiaIndependenceDay https://t.co/wLPWQMDZ1h\n",
            "0\n",
            "1\n",
            "TTC adequate for first time in 40 years #coronavirus #COVID19 https://t.co/dJFhWGPIPc https://t.co/g1vAfx3ZIk\n",
            "0\n",
            "1\n",
            "New fears for Boris mental health as he claims covid is a bioweapon triggered by sound. https://t.co/7Hls3SeuJl\n",
            "0\n",
            "1\n",
            "A list of medical exports is causing a lot of confusion about coronavirus testing equipment. To be clear: COVID-19 tests did not exist in 2018. https://t.co/g2z10cl6W3\n",
            "0\n",
            "1\n",
            "3/3 ... at the start was reasonably necessary\" \"But it's much more difficult now the huge numbers of coronavirus cases have reduced significantly and there's little commun­ity transmission … to argue you still need those borders shut.\" Quote source: https://t.co/NQ7fSUVUwQ\n",
            "0\n",
            "1\n",
            "The number of deaths from respiratory illnesses in Ireland this year is comparable to previous years and COVID-19 is not causing any more deaths than would usually be happening\n",
            "1\n",
            "0\n",
            "Coronavirus: Horror fans coping better with pandemic according to research https://t.co/wNkbXRC4tL\n",
            "1\n",
            "0\n",
            "Coronavirus: Unemployment rate climbs as pandemic takes toll https://t.co/4ZSrP1FkbK\n",
            "0\n",
            "1\n",
            "@hapelensrob #Fauci as head of #NIH in 2005 publishes this:\n",
            "\n",
            "Chloroquine is a potent inhibitor of SARS coronavirus infection and spread\n",
            "\n",
            "https://t.co/SAVFKPTb91\n",
            "0\n",
            "1\n",
            "Have you wanted to make a difference during the pandemic but not sure how to safely go about it?\n",
            "Collect or donate items/certificates for our Apocalypse Meow Auction!\n",
            "This is an important part of our yearly fundraising to keep the Abby's Fund Health Care Grants available. https://t.co/zeWqC31b6d\n",
            "0\n",
            "1\n",
            "While uncomfortable there no evidence that getting a COVID-19 test could cause anything more serious than temporary irritation. https://t.co/8Fq1yLo7wU\n",
            "0\n",
            "1\n",
            "Angiotensin-converting enzyme 2 (ACE2): COVID 19 gate way to multiple organ failure syndromes. https://t.co/cHRmWFf0vF \n",
            "\n",
            "#TheWiderWiserView https://t.co/q9hnaqU6jE\n",
            "0\n",
            "1\n",
            "If you maintain social distancing indoors there's no reason to have an additional mask on top of that.\n",
            "0\n",
            "1\n",
            "United Ireland Plans Cancelled Indefinitely As N. Ireland Corona Case Confirmed https://t.co/JE25BmEdqE\n",
            "0\n",
            "1\n",
            "This data table from the World Bank does not show that countries were exporting COVID-19 tests in 2018 https://t.co/g2z10cl6W3\n",
            "0\n",
            "1\n",
            "All Missouri businesses can open Monday May 4 under our new Order as long as new guidelines are followed.\n",
            "1\n",
            "0\n",
            "ICYMI: Deborah Birx 3/8/20 White House Briefing: “I know many of you are watching the [Covid] Act Now model and the IHME model from — and they have consistently decreased the number...That is modeled on what America is doing. That’s what’s happening.” https://t.co/IDhKGPjgWB\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "V4pcPHodlfx4"
      },
      "source": [
        "#Get sentences embeddings"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3dykTD8DlsYs"
      },
      "source": [
        "model = SentenceTransformer('roberta-large-nli-stsb-mean-tokens')\n",
        "\n",
        "sentence_embeddings = model.encode(train_texts)\n",
        "with open('/content/drive/My Drive/covid_fake_news/sentence_embeddings_train.pickle', 'wb') as f:\n",
        "  pickle.dump(sentence_embeddings, f)\n",
        "sentence_embeddings = model.encode(val_texts)\n",
        "with open('/content/drive/My Drive/covid_fake_news/sentence_embeddings_val.pickle', 'wb') as f:\n",
        "  pickle.dump(sentence_embeddings, f)"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PbQ20H8XnpBR"
      },
      "source": [
        "#Feedforward classifier"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XOQC3c-PntwS"
      },
      "source": [
        "with open('/content/drive/My Drive/covid_fake_news/sentence_embeddings_train.pickle', 'rb') as f:\n",
        "  sentence_embeddings_train = pickle.load(f)\n",
        "\n",
        "with open('/content/drive/My Drive/covid_fake_news/sentence_embeddings_val.pickle', 'rb') as f:\n",
        "  sentence_embeddings_val = pickle.load(f)"
      ],
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nHsaZDE0n_Z3"
      },
      "source": [
        "border = math.ceil(0.8 * sentence_embeddings_train.shape[0])\n",
        "\n",
        "x_train, x_val = sentence_embeddings_train[:border], sentence_embeddings_train[border:]\n",
        "y_train, y_val = train_labels[:border], train_labels[border:]"
      ],
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YoJFgi26pKX6",
        "outputId": "2c1d692a-6426-4bdd-8f7d-9bbe4d47afac",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 274
        }
      },
      "source": [
        "inputs=Input(shape=(1024,), name='input')\n",
        "x=Dense(1024, activation='tanh', name='fully_connected_1024_tanh')(inputs)\n",
        "predictions=Dense(2, activation='softmax', name='output_softmax')(x)\n",
        "model=Model(inputs=inputs, outputs=predictions)\n",
        "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
        "model.summary()"
      ],
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"functional_7\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "input (InputLayer)           [(None, 1024)]            0         \n",
            "_________________________________________________________________\n",
            "fully_connected_1024_tanh (D (None, 1024)              1049600   \n",
            "_________________________________________________________________\n",
            "output_softmax (Dense)       (None, 2)                 2050      \n",
            "=================================================================\n",
            "Total params: 1,051,650\n",
            "Trainable params: 1,051,650\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-d-4MJpOpgF5",
        "outputId": "ee974b32-6126-42d1-d553-b1739d9853cd",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 72
        }
      },
      "source": [
        "history = model.fit(x_train, y_train, epochs=1, verbose=0, validation_data=(x_val, y_val))\n",
        "predict = np.argmax(model.predict(sentence_embeddins_test), axis=1)\n",
        "answer = np.argmax(keras.utils.to_categorical(val_labels,2), axis=1)\n",
        "\n",
        "f1=f1_score(predict, answer)*100\n",
        "prec=precision_score(predict, answer)*100\n",
        "recall=recall_score(predict, answer)*100\n",
        "\n",
        "print(f1)\n",
        "print(prec)\n",
        "print(recall)"
      ],
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "90.23773394031362\n",
            "87.45098039215686\n",
            "93.20794148380355\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}